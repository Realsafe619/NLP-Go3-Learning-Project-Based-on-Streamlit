# pages/8_NLP_Application.py

import streamlit as st
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import pickle
from utils.user_auth import is_authenticated, get_current_username
from utils.llm_api import call_qwen_api # å‡è®¾ä½ å·²å°è£…å¥½ Qwen API

# --- ä¸ºäº†ç®€åŒ–ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨ Word2Vec å’Œ LSTM è¿›è¡Œå®Œæ•´è®­ç»ƒ ---
# --- è¿™é‡Œä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„ TF-IDF + LR æ¨¡å‹ä½œä¸ºç¤ºä¾‹ ---
# --- ä½ å¯ä»¥æ ¹æ® HW02 å’Œ HW03 çš„ä»£ç æ¥æ„å»º Word2Vec+LSTM æ¨¡å‹ ---
# --- ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„ç¤ºä¾‹æ¨¡å‹ ---
def create_simple_sentiment_model():
    """åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æƒ…æ„Ÿåˆ†ææ¨¡å‹ (ä»…ç”¨äºæ¼”ç¤º)"""
    # ç¤ºä¾‹è®­ç»ƒæ•°æ®
    texts = [
        "è¿™å®¶é…’åº—çœŸä¸é”™ï¼ŒæœåŠ¡æ€åº¦å¾ˆå¥½ï¼Œç¯å¢ƒä¼˜ç¾ï¼Œä¸‹æ¬¡è¿˜ä¼šæ¥ã€‚",
        "æˆ¿é—´å¹²å‡€ï¼Œä½ç½®æ–¹ä¾¿ï¼Œæ—©é¤å¾ˆæ£’ã€‚",
        "éå¸¸æ»¡æ„çš„ä¸€æ¬¡ä½å®¿ä½“éªŒã€‚",
        "æˆ¿é—´å¾ˆå¤§ï¼Œè®¾æ–½é½å…¨ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ã€‚",
        "å‰å°å°å§å§å¾ˆçƒ­æƒ…ï¼Œè§£å†³äº†æˆ‘çš„é—®é¢˜ã€‚",
        "éå¸¸ç³Ÿç³•çš„ä½“éªŒï¼Œæˆ¿é—´åˆå°åˆè„ã€‚",
        "æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œè®©äººå¾ˆå¤±æœ›ã€‚",
        "æˆ¿é—´è®¾æ–½è€æ—§ï¼Œéš”éŸ³æ•ˆæœä¸å¥½ã€‚",
        "ä»·æ ¼å¤ªè´µï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚",
        "å«ç”Ÿæ¡ä»¶å ªå¿§ï¼Œä¸ä¼šå†æ¥äº†ã€‚"
    ]
    labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0] # 1: æ­£é¢, 0: è´Ÿé¢

    # ç®€å•çš„é¢„å¤„ç† (å®é™…é¡¹ç›®ä¸­éœ€è¦æ›´å¤æ‚çš„é¢„å¤„ç†)
    processed_texts = [t.replace('ï¼Œ', ' ').replace('ã€‚', ' ').replace('ï¼', ' ').replace('ï¼Ÿ', ' ') for t in texts]
    
    # TF-IDF å‘é‡åŒ–
    vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2))
    X = vectorizer.fit_transform(processed_texts)

    # è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
    model = LogisticRegression()
    model.fit(X, labels)
    
    # ä¿å­˜æ¨¡å‹å’Œå‘é‡åŒ–å™¨ (æ¨¡æ‹Ÿä¿å­˜è¿‡ç¨‹)
    # ä½ å¯ä»¥å°†å®ƒä»¬ä¿å­˜åˆ° utils æˆ– user_data ç›®å½•ä¸‹
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›å®ƒä»¬
    return vectorizer, model

# --- æ¨¡æ‹ŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ ---
# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šä»æ–‡ä»¶åŠ è½½ç”¨æˆ·è®­ç»ƒå¥½çš„æ¨¡å‹æˆ–é¢„è®­ç»ƒæ¨¡å‹
# vectorizer, sentiment_model = load_pretrained_sentiment_model()
vectorizer, sentiment_model = create_simple_sentiment_model()

# --- Flair NER æ¨¡å‹åŠ è½½ ---
# æ³¨æ„ï¼šFlair æ¨¡å‹è¾ƒå¤§ï¼Œé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½
# åœ¨å®é™…éƒ¨ç½²æ—¶ï¼Œç¡®ä¿ç¯å¢ƒå·²å®‰è£… flair
try:
    from flair.models import SequenceTagger
    from flair.data import Sentence
    ner_tagger = SequenceTagger.load('ner') # åŠ è½½è‹±æ–‡ NER æ¨¡å‹
    flair_available = True
except ImportError:
    st.warning("Flair åº“æœªå®‰è£…ï¼ŒNER åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ 'pip install flair'")
    flair_available = False
except Exception as e:
    st.error(f"åŠ è½½ Flair NER æ¨¡å‹æ—¶å‡ºé”™: {e}")
    flair_available = False

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="NLP åº”ç”¨ä»»åŠ¡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- æƒé™æ£€æŸ¥ ---
if not is_authenticated():
    st.error("âš ï¸ è¯·å…ˆç™»å½•ä»¥è®¿é—®æ­¤åŠŸèƒ½ã€‚")
    st.stop()

# --- ä¸»é¡µé¢æ ‡é¢˜ ---
st.title("ğŸ¤– NLP åº”ç”¨ä»»åŠ¡")

# --- åˆ›å»ºé€‰é¡¹å¡ ---
tab1, tab2 = st.tabs(["ğŸ˜Š æƒ…æ„Ÿåˆ†æ", "ğŸ·ï¸ å‘½åå®ä½“è¯†åˆ«"])

# ==================== Tab 1: æƒ…æ„Ÿåˆ†æ ====================
with tab1:
    st.header("æƒ…æ„Ÿåˆ†æ (Sentiment Analysis)")
    st.write("åˆ¤æ–­è¾“å…¥æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆå¦‚æ­£é¢/è´Ÿé¢ï¼‰ã€‚")

    # ç”¨æˆ·è¾“å…¥
    user_text_sentiment = st.text_area("è¯·è¾“å…¥å¾…åˆ†æçš„æ–‡æœ¬ï¼ˆå¦‚è¯„è®ºï¼‰:", height=100, key="sentiment_input")

    # é€‰æ‹©æ¨¡å‹
    model_options_sentiment = ["TF-IDF + é€»è¾‘å›å½’ (ç¤ºä¾‹)"]
    if flair_available:
        model_options_sentiment.append("Flair (NER æ¨¡å‹ï¼Œç¤ºä¾‹ï¼Œç”¨äºæ¼”ç¤ºè°ƒç”¨)")
    model_options_sentiment.append("å¤§æ¨¡å‹ (Qwen)")
    selected_model_sentiment = st.selectbox("é€‰æ‹©æƒ…æ„Ÿåˆ†ææ¨¡å‹:", model_options_sentiment)

    if st.button("åˆ†ææƒ…æ„Ÿ", key="analyze_sentiment"):
        if not user_text_sentiment.strip():
            st.error("è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬ã€‚")
        else:
            with st.spinner(f"ä½¿ç”¨ {selected_model_sentiment} åˆ†æä¸­..."):
                if selected_model_sentiment == "TF-IDF + é€»è¾‘å›å½’ (ç¤ºä¾‹)":
                    # é¢„å¤„ç†è¾“å…¥æ–‡æœ¬
                    processed_input = user_text_sentiment.replace('ï¼Œ', ' ').replace('ã€‚', ' ').replace('ï¼', ' ').replace('ï¼Ÿ', ' ')
                    # å‘é‡åŒ–
                    input_vec = vectorizer.transform([processed_input])
                    # é¢„æµ‹
                    prediction = sentiment_model.predict(input_vec)[0]
                    probability = sentiment_model.predict_proba(input_vec)[0]
                    
                    # æ˜¾ç¤ºç»“æœ
                    sentiment_label = "æ­£é¢" if prediction == 1 else "è´Ÿé¢"
                    confidence = max(probability)
                    st.success(f"é¢„æµ‹æƒ…æ„Ÿ: **{sentiment_label}**")
                    st.write(f"ç½®ä¿¡åº¦: {confidence:.2f}")
                    # ç®€å•çš„æ¦‚ç‡åˆ†å¸ƒ
                    st.write("**æ¦‚ç‡åˆ†å¸ƒ:**")
                    prob_df = pd.DataFrame({
                        "æƒ…æ„Ÿ": ["è´Ÿé¢", "æ­£é¢"],
                        "æ¦‚ç‡": probability
                    })
                    st.bar_chart(prob_df.set_index("æƒ…æ„Ÿ"))

                elif selected_model_sentiment == "Flair (NER æ¨¡å‹ï¼Œç¤ºä¾‹ï¼Œç”¨äºæ¼”ç¤ºè°ƒç”¨)":
                    # Flair ä¸»è¦ç”¨äº NERï¼Œè¿™é‡Œåªæ˜¯æ¼”ç¤ºå¦‚ä½•è°ƒç”¨å…¶ä»–æ¨¡å‹
                    # å¯¹äºæƒ…æ„Ÿåˆ†æï¼ŒFlair ä¹Ÿæœ‰ç›¸åº”æ¨¡å‹ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ç”¨å®ƒæ¥æ¼”ç¤º
                    if flair_available:
                        sentence = Sentence(user_text_sentiment)
                        # Flair NER é€šå¸¸ä¸ç›´æ¥è¾“å‡ºæƒ…æ„Ÿï¼Œè¿™é‡Œä»…æ¼”ç¤ºè°ƒç”¨
                        # st.info("Flair NER æ¨¡å‹å·²åŠ è½½ï¼Œä½†æ­¤ç¤ºä¾‹ä¸ç”¨äºæƒ…æ„Ÿåˆ†æã€‚")
                        # ä½ å¯ä»¥åŠ è½½ Flair çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼Œä¾‹å¦‚ 'sentiment-fast'
                        try:
                            from flair.models import TextClassifier
                            flair_sentiment_model = TextClassifier.load('sentiment')
                            flair_sentiment_model.predict(sentence)
                            # è§£æç»“æœ
                            flair_result = sentence.labels[0].value
                            flair_confidence = sentence.labels[0].score
                            st.success(f"Flair é¢„æµ‹æƒ…æ„Ÿ: **{flair_result}**")
                            st.write(f"ç½®ä¿¡åº¦: {flair_confidence:.2f}")
                        except Exception as e:
                             st.error(f"ä½¿ç”¨ Flair æƒ…æ„Ÿåˆ†ææ¨¡å‹æ—¶å‡ºé”™: {e}")
                             st.info("Flair æƒ…æ„Ÿåˆ†ææ¨¡å‹å¯èƒ½éœ€è¦é¢å¤–å®‰è£…æˆ–åŠ è½½ï¼Œè¯·å‚è€ƒ Flair æ–‡æ¡£ã€‚")
                    else:
                        st.error("Flair æœªå®‰è£…æˆ–æ¨¡å‹åŠ è½½å¤±è´¥ã€‚")

                elif selected_model_sentiment == "å¤§æ¨¡å‹ (Qwen)":
                    # æ„å»ºæç¤ºè¯ï¼Œè®©å¤§æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
                    prompt = f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ï¼Œå¹¶ç»™å‡ºç®€çŸ­çš„ç†ç”±ï¼š\n\næ–‡æœ¬: {user_text_sentiment}"
                    success, response = call_qwen_api([{"role": "user", "content": prompt}])
                    if success:
                        st.write("**å¤§æ¨¡å‹åˆ†æç»“æœ:**")
                        st.write(response)
                    else:
                        st.error(f"è°ƒç”¨å¤§æ¨¡å‹ API å¤±è´¥: {response}")


# ==================== Tab 2: å‘½åå®ä½“è¯†åˆ« (NER) ====================
with tab2:
    st.header("å‘½åå®ä½“è¯†åˆ« (Named Entity Recognition, NER)")
    st.write("è¯†åˆ«å¹¶æ ‡æ³¨æ–‡æœ¬ä¸­çš„äººåã€åœ°åã€ç»„ç»‡åç­‰å®ä½“ã€‚")

    # ç”¨æˆ·è¾“å…¥
    user_text_ner = st.text_area("è¯·è¾“å…¥å¾…è¯†åˆ«çš„æ–‡æœ¬:", height=100, key="ner_input")

    # é€‰æ‹©æ¨¡å‹
    model_options_ner = []
    if flair_available:
        model_options_ner.append("Flair (BiLSTM-CRF)")
    model_options_ner.append("å¤§æ¨¡å‹ (Qwen)")
    selected_model_ner = st.selectbox("é€‰æ‹© NER æ¨¡å‹:", model_options_ner)

    if st.button("è¯†åˆ«å®ä½“", key="run_ner"):
        if not user_text_ner.strip():
            st.error("è¯·è¾“å…¥è¦è¯†åˆ«çš„æ–‡æœ¬ã€‚")
        else:
            with st.spinner(f"ä½¿ç”¨ {selected_model_ner} è¯†åˆ«ä¸­..."):
                if selected_model_ner == "Flair (BiLSTM-CRF)":
                    if flair_available:
                        sentence = Sentence(user_text_ner)
                        ner_tagger.predict(sentence)

                        # æå–å®ä½“å’Œæ ‡ç­¾
                        entities = [(entity.text, entity.tag, entity.score) for entity in sentence.get_spans('ner')]
                        
                        if entities:
                            st.success("è¯†åˆ«åˆ°ä»¥ä¸‹å®ä½“:")
                            # åˆ›å»º DataFrame ä¾¿äºå±•ç¤º
                            entities_df = pd.DataFrame(entities, columns=["å®ä½“", "ç±»å‹", "ç½®ä¿¡åº¦"])
                            st.dataframe(entities_df)
                            
                            # ç®€å•çš„å¯è§†åŒ–ï¼šåœ¨æ–‡æœ¬ä¸­é«˜äº®å®ä½“
                            highlighted_text = user_text_ner
                            for entity_text, entity_tag, _ in sorted(entities, key=lambda x: x[0], reverse=True): # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ç´¢å¼•å˜åŒ–
                                # è¿™é‡Œä½¿ç”¨ç®€å•çš„ HTML æ ‡ç­¾è¿›è¡Œé«˜äº®ï¼Œéœ€è¦ st.markdown(unsafe_allow_html=True)
                                # ä¸ºäº†å®‰å…¨ï¼Œä¹Ÿå¯ä»¥ç”¨å…¶ä»–æ–¹å¼ï¼Œå¦‚åœ¨æ–‡æœ¬æ—è¾¹æ ‡æ³¨
                                # highlighted_text = highlighted_text.replace(entity_text, f"<mark>{entity_text} ({entity_tag})</mark>")
                                pass # æš‚ä¸å®ç° HTML é«˜äº®ï¼Œå› ä¸ºæœ‰å®‰å…¨é£é™©

                            # ç”¨ Pandas è¡¨æ ¼å±•ç¤ºå¸¦æ ‡ç­¾çš„è¯
                            tokens_with_tags = [(token.text, token.get_tag('ner').value) for token in sentence]
                            tokens_df = pd.DataFrame(tokens_with_tags, columns=["Token", "NER Tag"])
                            # è¿‡æ»¤æ‰éå®ä½“çš„æ ‡ç­¾ (O)
                            entities_only_df = tokens_df[tokens_df['NER Tag'] != 'O']
                            if not entities_only_df.empty:
                                st.subheader("å®ä½“è¯¦æƒ…:")
                                st.dataframe(entities_only_df)
                            else:
                                st.info("æœªè¯†åˆ«åˆ°å‘½åå®ä½“ã€‚")

                        else:
                            st.info("æœªè¯†åˆ«åˆ°å‘½åå®ä½“ã€‚")
                    else:
                        st.error("Flair æœªå®‰è£…æˆ–æ¨¡å‹åŠ è½½å¤±è´¥ã€‚")

                elif selected_model_ner == "å¤§æ¨¡å‹ (Qwen)":
                    # æ„å»ºæç¤ºè¯ï¼Œè®©å¤§æ¨¡å‹è¿›è¡Œ NER
                    prompt = f"è¯·è¯†åˆ«ä»¥ä¸‹æ–‡æœ¬ä¸­çš„å‘½åå®ä½“ï¼ˆå¦‚äººå PERã€åœ°å LOCã€ç»„ç»‡å ORG ç­‰ï¼‰ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼š\n\næ–‡æœ¬: {user_text_ner}\n\nè¾“å‡ºæ ¼å¼ç¤ºä¾‹: {{'entities': [{'text': 'å®ä½“æ–‡æœ¬', 'label': 'å®ä½“ç±»å‹', 'start': å¼€å§‹ä½ç½®, 'end': ç»“æŸä½ç½®}]}}"
                    success, response = call_qwen_api([{"role": "user", "content": prompt}])
                    if success:
                        st.write("**å¤§æ¨¡å‹è¯†åˆ«ç»“æœ:**")
                        st.json(response) # å‡è®¾å¤§æ¨¡å‹è¿”å›äº† JSON æ ¼å¼
                        # ä½ å¯èƒ½éœ€è¦è§£æ response å­—ç¬¦ä¸²ä¸º JSON å¯¹è±¡ï¼Œç„¶åå¤„ç†
                        # try:
                        #     parsed_response = json.loads(response)
                        #     # ... è§£æå’Œå±•ç¤ºé€»è¾‘ ...
                        # except json.JSONDecodeError:
                        #     st.write(response) # å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥æ˜¾ç¤º
                    else:
                        st.error(f"è°ƒç”¨å¤§æ¨¡å‹ API å¤±è´¥: {response}")

# --- ä¿¡æ¯æç¤º ---
st.divider()
st.info("ğŸ’¡ æç¤ºï¼šæ­¤é¡µé¢é›†æˆäº†å¤šç§ NLP åº”ç”¨ä»»åŠ¡ã€‚æƒ…æ„Ÿåˆ†æå’Œ NER çš„æ¨¡å‹å®ç°å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å’Œæ‰©å±•ã€‚")
